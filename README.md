# Perceptron-Learning-Algorithm

## ðŸ¤– Perceptron Learning Algorithm â€“ 3D Classification
This project explores the implementation and analysis of the Perceptron Learning Algorithm for binary classification tasks on 3-dimensional data points. It is divided into three parts: training the perceptron, analyzing linear separability, and evaluating convergence behavior.
### 2a: Perceptron Training Algorithm
Implements the single-layer perceptron for 3D inputs.

Classifies data into two binary classes.

Weights are updated iteratively until convergence (or maximum epochs).
### 2b: Linearly Separable Combinations
Given a dataset of 3D points, the program generates all binary class combinations.

Determines which combinations are linearly separable using the perceptron.

Useful for evaluating dataset structure and learning feasibility.

### 2c: Convergence and Learning Rate Analysis
Tests different learning rates (e.g., 0.01 to 1.0) and epoch limits.

Tracks:

Number of epochs to convergence

Final classification accuracy

Useful for tuning perceptron performance and visualizing convergence behavior
### ðŸ”§ Technologies Used
Python 3.x

NumPy

Matplotlib (for optional visualization)

## ðŸ“ˆ Output Examples
Weight vectors and final decision boundaries

Number of separable class combinations

Convergence plots of accuracy vs epochs

## âœ… Conclusion
This project gives hands-on understanding of the Perceptron Learning Algorithm, especially for 3D data. It shows how the model converges, which class combinations are linearly separable, and how hyperparameters affect training. A strong foundation for understanding neural networks and classification theory.


